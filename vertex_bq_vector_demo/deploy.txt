Option 1: Port Forwarding via Cloud Shell (Simplest)

Start your Streamlit app in the notebook terminal:

bashstreamlit run your_app.py --server.port 8501

Set up port forwarding using Cloud Shell:

Open Cloud Shell in GCP Console
Run this command:



bashgcloud compute ssh YOUR_INSTANCE_NAME \
  --project YOUR_PROJECT_ID \
  --zone YOUR_ZONE \
  -- -L 8501:localhost:8501

Click "Web Preview" in Cloud Shell â†’ Preview on port 8501

Option 2: Using Vertex AI Workbench's Built-in Proxy
Vertex AI Workbench instances have a reverse proxy that allows access to specific ports.

Start Streamlit with a specific configuration:

bashstreamlit run your_app.py \
  --server.port 8501 \
  --server.address 0.0.0.0 \
  --server.baseUrlPath /proxy/8501 \
  --server.enableCORS false \
  --server.enableXsrfProtection false
```

2. **Access via the proxy URL:**
```
https://YOUR_INSTANCE_ID.notebooks.googleusercontent.com/proxy/8501/
You can find your instance URL in the Workbench UI - it's the JupyterLab URL but replace /lab with /proxy/8501/
Option 3: Create a Custom Startup Script (Best for Regular Use)
Create a script to automatically start Streamlit:

Create start_streamlit.sh:

bash#!/bin/bash
cd /home/jupyter/your_project_directory
streamlit run your_app.py \
  --server.port 8501 \
  --server.address 0.0.0.0 \
  --server.baseUrlPath /proxy/8501 \
  --server.enableCORS false \
  --server.enableXsrfProtection false \
  --server.headless true

Make it executable and run:

bashchmod +x start_streamlit.sh
nohup ./start_streamlit.sh > streamlit.log 2>&1 &
```

3. **Access at:**
```
https://YOUR_INSTANCE_ID.notebooks.googleusercontent.com/proxy/8501/
Option 4: Using Cloud Run (Production Deployment)
For production or sharing with others:

Create a Dockerfile:

dockerfileFROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8080

CMD streamlit run your_app.py \
    --server.port 8080 \
    --server.address 0.0.0.0 \
    --server.headless true

Deploy to Cloud Run:

bashgcloud run deploy streamlit-app \
  --source . \
  --region us-central1 \
  --allow-unauthenticated
Quick Troubleshooting
If you can't access Streamlit:

Check if Streamlit is running:

bashps aux | grep streamlit
netstat -tulpn | grep 8501

Check firewall rules:

bash# In your notebook
curl http://localhost:8501

View Streamlit logs:

bashtail -f streamlit.log
# or
streamlit run your_app.py --server.port 8501 --logger.level=debug

Get your exact proxy URL:

python# Run in a notebook cell
import os
import socket

hostname = socket.gethostname()
print(f"Access Streamlit at:")
print(f"https://{hostname}.notebooks.googleusercontent.com/proxy/8501/")
Example Complete Workflow
Here's a complete example to get you started:
bash# 1. Install Streamlit (if not already installed)
pip install streamlit

# 2. Create a simple test app
cat > test_app.py << 'EOF'
import streamlit as st

st.title("Vertex AI Streamlit Test")
st.write("Hello from Vertex AI Workbench!")

if st.button("Click me"):
    st.success("It works!")
EOF

# 3. Start Streamlit
streamlit run test_app.py \
  --server.port 8501 \
  --server.address 0.0.0.0 \
  --server.baseUrlPath /proxy/8501 \
  --server.enableCORS false \
  --server.enableXsrfProtection false &

# 4. Get your URL
python3 << 'EOF'
import socket
hostname = socket.gethostname()
print(f"\nğŸˆ Access your Streamlit app at:")
print(f"https://{hostname}.notebooks.googleusercontent.com/proxy/8501/\n")
EOF
Recommended Approach
For development in Vertex AI Workbench: Use Option 2 (built-in proxy)
For production or sharing: Use Option 4 (Cloud Run)
Which option would you like to implement? I can provide more specific guidance based on your setup.